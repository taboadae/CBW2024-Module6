---
title: "Module 6 Lab: Bacterial cgMLST analysis"
authors: "Guangzhi Zhang, Jimmy Liu, and Eduardo Taboada"
date: "2024-05-15"
output:
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F)
```

# Background

Our overall aim for this computer lab is to perform core genome Multi-Locus Sequencing Typing (**cgMLST**) analysis, a genome-based typing method widely adopted in bacterial genomic surveillance networks across the globe. 

As discussed in the lecture, the widespread adoption of cgMLST is due in large part to recent advances in high-throughput sequencing, which have enabled the routine deployment of whole genome sequencing (**WGS**) in microbial surveillance. Concomitant with the wider availability of WGS data has been the need to develop approaches to analyze these data. Part of this effort has centered on adapting the Multi-Locus Sequence Typing approach originally described by [Maiden et al. (1998)](https://pubmed.ncbi.nlm.nih.gov/9501229/) to genome scales and coupling it to existing microbial surveillance infrastructure. The implementation of cgMLST by the PulseNet Canada and the wider PulseNet International network for foodborne outbreak surveillance has made it possible for WGS data to be used as evidence in public health investigations and [public health interventions](https://inspection.canada.ca/preventive-controls/meat/salmonella-in-frozen-raw-breaded-chicken/faq/eng/1554140834819/1554140994648).

You will conduct a retrospective analysis on data from a hypothetical enteric pathogen that is primarily transmitted to humans through the consumption of contaminated foods and water. The dataset comprises allele data and contextual metadata on isolates collected from human and non-human surveillance and may include potential outbreaks. We have provided you with this `R markdown` file composed of a custom workflow written in the R language for statistical computing that includes modules to perform various steps in genomic epidemiologic analysis using cgMLST data. The workflow comprises: 

1. Identifying low quality, accessory and core loci in the dataset
2. Identifying genomes with low quality allele profiles and dataset quality control
3. Computing cgMLST distances using the Hamming distance 
4. Hierarchical clustering of cgMLST distance matrices
5. Extracting genomic clusters at different similarity thresholds
6. Analyzing genomic clusters for variables of interest
7. Visualizing basic dendrograms annotated with epidemiological metadata

Your challenge will be to leverage the tools and data at your disposal to establish high quality cgMLST profiles that can be used to infer genetic relatedness and to explore patterns in the data in order to synthesize possible interpretations based on all available genomic and epidemiological data, including possible outbreaks and their potential sources.


## Learning Objectives

-   The significance of metrics used for cgMLST quality control
-   Core and accessory loci and their use in MLST analysis
-   Computing similarity matrices and building dendrograms from MLST data
-   Distance thresholding to generate genomic clusters for downstream analyses
-   Using the ggtree R library for tree visualizations
-   Linking epidemiological data to dendrograms to infer possible outbreak scenarios 


## Time line for training

### Day 1: Pre-processing and preliminary analyses

**a. Dataset QC & curation based on allele completion rates**

-   Analysis of allele completion rates for each locus to define core loci (+ accessory loci) for cgMLST
-   For each genome, analysis of completion rates of core loci to flag low-quality genomes for exclusion
-   Finalization of dataset --> genomes with good completion rate metrics for core loci


**b. Clustering of dataset**

-   Generation of Hamming distance matrix
-   Hierarchical clustering of Hamming distance matrix

**c. Genomic cluster extraction at multiple thresholds**

-   Extraction of genomic cluster membership at all possible similarity thresholds
-   Extraction of genomic cluster membership at key similarity thresholds

**d. Evaluation of genomic clusters (Part 1)**

-   Analysis of genomic clusters using metadata variables of interest via summary tables


### Day 2: Visualizations to facilitate analysis

**a. Evaluation of genomic clusters (Part 2)**

-   Analysis of genomic clusters using metadata variables of interest via stacked histogram

**b. Visualizations using full dendrograms**

-   Visualization of clustered distance matrix as a heatmap
-   Visualization of annotated radial and rectangular dendrograms
-   Visualization of individual genomic clusters using annotated sub-trees

The code is intended so that it can be re-used on similar allelic data. This dataset consists of allelic profiles from isolates recovered from samples collected from a diverse range of geographical regions in Canada, different sources, and dating back to the early 2000s. 


> Because generating assemblies from raw reads and allele calling are computationally and time-intensive steps in the analysis, in this exercise we will be using pre-computed allelic data generated from WGS assemblies using the commercial software BioNumerics, which is currently used by the PulseNet International network.



## Getting Started

Let's begin by installing (if needed) and loading all R packages and helper scripts required to run all the code in this lab.

> [Every time you begin a new R session, you must reload all the packages and scripts!]{.underline}

```{r install and load pkgs and helper scripts}
# install packages requiring BiocManager 

if (!requireNamespace('BiocManager', quietly = TRUE))
    install.packages('BiocManager')

if (!requireNamespace('ComplexHeatmap', quietly = TRUE))
    BiocManager::install('ComplexHeatmap')

if (!requireNamespace('treedataverse', quietly = TRUE))
    BiocManager::install("YuLab-SMU/treedataverse")

# install other packages

required_packages <- c("tidyverse", "data.table", "BiocManager", "plotly", "ggnewscale", "circlize",
                      "randomcoloR", "phangorn", "knitr", "purrr", "here", "scales", "remotes","reactable")

not_installed <- required_packages[!required_packages %in% installed.packages()[,"Package"]]

if (length(not_installed) > 0) {
  install.packages(not_installed, quiet = TRUE)
}


# load packages 

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(treedataverse))
suppressPackageStartupMessages(library(plotly))
suppressPackageStartupMessages(library(ggnewscale))
suppressPackageStartupMessages(library(ComplexHeatmap))
suppressPackageStartupMessages(library(circlize))
suppressPackageStartupMessages(library(randomcoloR))
suppressPackageStartupMessages(library(RColorBrewer))
suppressPackageStartupMessages(library(phangorn))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(purrr))
suppressPackageStartupMessages(library(scales))
suppressPackageStartupMessages(library(reactable))

## source helper R scripts
source("src/ggtree_helper.R")
source("src/cluster_count_helper.R")
source("src/cluster_helper.R")
source("src/cgmlst_helper.R")

```


Next, read the wgMLST data and metadata into memory using `fread()` from the `data.table` package. the input data are located in the folder `data`


```{r load data}

# define path for wgmlst data and metadata using here() from 'here' package

wgmlst_path <- here("data","wgMLST_calls","wgMLST.tsv")

meta_path <- here("data","metadata","meta_all.tsv")

## load wgMLST data

wgMLST <- fread(wgmlst_path,sep = "\t")

meta<- fread(meta_path,sep = "\t")

```

> [Throughout this markdown file, editable parts of the code (e.g. parameters, commands) have been highlighted in the code chunks via commenting.]{.underline} You are highly encouraged to adjust them to observe how different parameters affect the outcome.


## Day 1: Pre-processing and preliminary analyses

### Compute completeness for all loci based on initial set of genomes

We first need to evaluate cgMLST data quality by applying criteria to determine whether the properties of the allele profiles meet quality standards. Incomplete genome assemblies will generate missing information in the form of unassigned allele calls when loci collide with gaps in assemblies. Accessory loci can similarly generate significant numbers of unsassigned alleles since they are not necessary present on a given genome. Even modest levels of unassigned alleles will compromise the precision of genetic similarity calculations used for inferring relationships between the various genomes in dataset. Hence, care must be taken to exclude loci/genomes with excessive levels of unassigned alleles. 

Our first step will be to compute basic allele completion stats on every locus and every genome in the dataset by running the code chunk below:


```{r  wgMLST loci compelteness,fig.width= 9, fig.height= 3.3}
# use compute_lc helper function to compute 
# allele assig*nment rate (completeness) 
# across all loci
loci_completeness <- compute_lc(wgMLST)

# write raw summary to quality_summary sub-folder in the output folder
write.table(loci_completeness, here("output","quality_summary","wgmlst_loci_quality.stats.tsv"),
            quote = F, row.names = F, sep = "\t")

# plot of allele distribution across genomes using function "plot_loci_completeness"


plot_loci_completeness(loci_completeness)

# print summary statistics for loci completeness
summary(loci_completeness)

```
> Note that **within the main R studio pane**, all plots can be popped out to a new window by clicking on the *left-most button at the top right of the plot*. **Questions:** Based on the table above, can you tell roughly how many loci have full assignment across the initial set of 402 genomes in the dataset? What breakdown of core/accessory genes can you predict at this stage of the analysis? Based on the plot, how many genomes would definitely need to be excluded based on exceeding a >1% missing allele threshold if all 1343 loci are used?


### cgMLST Quality Control

If an allele table contains **accessory loci**, these should be *excluded* from cgMLST analysis. Because they are *expected* to be found on an assembly of decent quality, **core loci** are an extremely powerful tool in the evaluation of genomes for QC. Part of the process of defining a **cgMLST schema** is in identifying the core loci to include (and the accessory loci to exclude!) from the analysis. The challenge lies with the fact that unless you have access to a pre-defined set of core loci via an existing [**cgMLST schema**](https://www.cgmlst.org/ncs), you must first define these core loci by using completeness in the dataset. However, genomes with an excess of unassigned alleles will result in the needless exclusion of loci wrongly flagged as accessory on the basis of incompleteness. At the same time, the inclusion of accessory loci during the quality assessment of genomes will result in the needless exclusion of genomes wrongly flagged as poor quality simply because of missing accessory loci. We're stuck in a classic case of trying to fly an airplane while flying it. 


> Accessory genes **can** be used in MLST analysis but their use must be highly prescribed. Although, as mentioned above, their presence on a given genome is a bit of a coin-flip, patterns of accessory gene presence *tend* to follow along genomic sublineages. So using accessory genomes to examine more limited subsets of highly-related genomes can provide additional discriminatory power. But when dealing with datasets of unknowns, core loci provide the most robust solution. 


The ultimate goal here is to define a set of core loci that can be used for genome QC. So we have to implement a phased-in approach to attempt to tease apart unassigned allele calls from accessory loci from unassigned calls due to incomplete assemblies. Here, we use the `compute_gc` helper function to compute the allele completion rate for each locus using a large sample that excludes genomes *suspected* to be of poor quality. We create this sample by applying a user-defined cut-off currently set to use the top 75% genomes in terms of overall allele calls (i.e. the *75% genome cohort*). This ensures that we side-step genomes with lots of unassigned allele calls since these will skew locus completeness, affecting the identification of core loci. This also ensures that a sufficiently large enough number of genomes is being used to define core loci that *should* be identifiable on a typical high quality genome in the dataset. Here, we define a core locus as **having a completion rate above 99.5% in the 75% genome cohort**. 

> The process to define a core schema that we describe here is a bit *ad hoc* but it will do in a pinch. We suggest using a more formal schema-building tool if you are embarking in the analysis of an oganism without one. For example, software tools like [**chewBBACCA**](https://chewbbaca.readthedocs.io/en/latest/user/getting_started/overview.html) have been developed to automate and bring rigor to the schema-building process. 


Once core loci have been identified, it's time to circle back and re-compute the completion rate for **these core loci only**. Because core loci *should* be present in every genome, any unassigned calls are due to genome quality issues. We thus apply a genome inclusion/exclusion quality threshold currently set to 99% so that **genomes with >1% unassigned core loci are excluded from further analysis**. 

The code chunk below proceeds through a series of steps to compute the frequency of unassigned alleles across each locus (i.e. columns) and each genome (i.e. rows) in the allele table. This information will be used to estimate a set of loci that are core to the genomes in the dataset, and these will subsequently inform the identification of poor quality loci/genomes to exclude from downstream analyses. 

```{r  define cgmlst core loci,compute core loci completion rate}
# Identification of core loci using compute_gc helper function 
genome_completion<- compute_gc(wgMLST)

# identify cohort of higher quality genomes to be used for assessing completion rate to identify core loci
top_genomes <- genome_completion%>%
                       arrange(desc(valid_alleles))%>%
                         slice(1:as.integer(nrow(genome_completion)*0.75)) # Adjustable parameter currently set to 75%

# filter for the top X% (e.g. 75%) of genomes based on overall allele completion
top_wgMLST <- wgMLST%>%
                   filter(ID%in%top_genomes$ID)

## compute allele assignment rate (i.e. completeness) using compute_lc helper for the top 75% cohort
top_genome_completion  <- compute_lc(top_wgMLST)

## define core_threshold and core loci using a user-defined comleteness threshold (e.g. 99.5%) using the top 75% cohort

core_loci  <- top_genome_completion %>%
                filter(completeness >99.5 ) ## Core loci defined as present in >99.5% of 75% cohort


# compute quality assessment (QA) for all genomes using the core_loci using the  compute_gc() helper 
cgmlst <- wgMLST%>%select(1, core_loci$locus)

cgmlst_genome_completion  <- compute_gc(cgmlst)


# define quality control (QC) threshold for the maximum percentage of missing cgMLST calls for inclusion/exclusion

QC_threshold <- as.integer(ncol(cgmlst)*0.01) + 1 ## Up to 1% missing core loci per genome allowed

## create cgMLST QC report (1: meets the QC standard, 0: fails the QC standard)
cgmlst_QC  <- cgmlst_genome_completion  %>%
                         mutate(QC_cgmlst = case_when(missing_alleles < QC_threshold ~ 1,
                                                       T ~ 0))
# output cgMLST quality file
write.table(cgmlst_QC, here("output","quality_summary","cgmlst_genome_qual.stats.tsv"),
            quote = F, row.names = F, sep = "\t")

# print data summary of cgmlst completeness

summary(cgmlst_genome_completion)

```
> **Questions:** The table above describes summary statistics for the set of core loci defined by the process for this particular dataset. Based on these data: how many core loci have been designated? How many genomes definitely pass a quality threshold based on < 1% missing alleles?


### Generate finalized dataset utilizing custom cgMLST schema based on the core loci identified above

We have identified core loci and have used them to assess genome quality on the original genomes in the dataset. It's time to put it all together and finalize the dataset by generating an  *x* by *y* allele table comprising the allelic profiles of *x* high quality genomes at *y* core loci by running the code chunk below:

```{r  select finalized cgMLST dataset and metadate}
# define final genomes that passed QC step
final_genomes <- cgmlst_QC %>%
                    filter(QC_cgmlst > 0)

# define final cgMLST allele table based on QC-passed genomes & core loci
cgmlst_final <- cgmlst%>%
                  filter(ID%in%final_genomes$ID)


# define final cgMLST meta data table by excluding QC-failed genomes
metadata <- meta %>% 
             filter(ID%in%cgmlst_final$ID)%>%
                mutate(across(everything(), as.character))
 
# write finalized cgMLST allele table and metadata table to files
write.table(cgmlst_final,  here("data","wgMLST_calls","cgmlst_final.tsv"),
            quote = F, row.names = F, sep = "\t")

write.table(metadata, here("data","metadata","cgmlst_final_metadata.tsv"),
            quote = F, row.names = F, sep = "\t")


# print filtering results
message(paste("Number of original loci:", ncol(wgMLST)-1))
message(paste("Number of core loci included:", ncol(cgmlst_final)-1))
message(paste("Number of accessory loci excluded:",ncol(wgMLST)- ncol(cgmlst_final)-1))
message(paste("Number of genomes before filter:", nrow(cgmlst_genome_completion)))
message(paste("Number of genomes after filter:", nrow(cgmlst_final)))
message(paste("Number of genomes removed:",nrow(cgmlst_genome_completion)-nrow(cgmlst_final)))

```
> **Questions:** How do your earlier predictions compare against these final numbers? i.e. did the process yield more accessory loci or high quality genomes than you predicted?



### Calculating the Hamming Distance

The traditional approach for cgMLST analysis is based on computing pairwise distances between allele profiles as a proxy for the underlying genetic similarity between two isolates. Below, you are introduced to a distance metric called the **Hamming distance**, which is based on computing the number of differences between a pair of character vectors. The Hamming distance is useful for comparing profiles where a majority of characters are defined, such as profiles comprising core loci. 

Given two character vectors of equal lengths, the Hamming distance is the total number of positions in which the two vectors are [different:]{.underline}


Profile A: `[ 0 , 2 , 0 , 5 , 5 , 0 , 0 , 0 , 0 ]`

Profile B: `[ 0 , 1 , 0 , 4 , 3 , 0 , 0 , 0 , 0 ]`

  A != B: `[ 0 , 1 , 0 , 1 , 1 , 0 , 0 , 0 , 0 ]`   

Hamming distance = `sum( A != B )` = 3


> In phylogenetic analysis, distance-based approaches are rather flexible in the sense that they can be constructed from any measure that estimates genetic similarity through the direct comparison of data points. In cgMLST, we compare allele profiles. In Mash, we compare k-mer profiles.


In the context of two cgMLST profiles, the Hamming distance is calculated based on the number of allele differences across all loci as a proportion of total number of loci evaluated. 

> cgMLST profiles are composed of mostly complete data. If you were to include accessory loci, not that you will, this will introduce substantial "null" or missing data. In such cases, distance metrics such as the **Jaccard distance** may be much more appropriate, although that is beyond the scope of this lab.

Hamming distances will be computed in an *all vs. all* fashion to generate a pairwise distance matrix that will subsequently serve as the input for distance-based tree-building algorithms. Run the following code chunk:

```{r}
# use hamming helper function to compute pairwise Hamming distance of final cgMLST dataset 

# loading user_defined cgMLST final dataset 
# cgmlst_final <- fread(here("data","wgMLST_calls","cgmlst_final.tsv"))

# compute Hamming distance 
# PATIENCE!!! this step might take several minutes depending on the size of the dataset

dist_mat <- cgmlst_final %>% 
  column_to_rownames("ID") %>% 
  t() %>% 
  hamming()

# the dimension should be symmetric and should be the size of dataset (i.e. number of QC-passed genomes)

dim(dist_mat)


```
> Nothing to see here...we print the matrix dimensions as a sanity check and to indicate the process is complete.

### Hierarchical Clustering of cgMLST profiles by Hamming distance
In this section we will be performing hierarchical clustering of the Hamming distance matrix using the [Unweighted Pair Group Method with Arithmetic Mean](https://en.wikipedia.org/wiki/UPGMA) (i.e. **UPGMA**) algorithm. *We're not going to lie.* UPGMA is just about the most basic and unsophisticated clustering algorithm out there. However, UPGMA is still widely used and is the default clustering implementation in the BioNumerics software currently used by PulseNet. 

> In the lecture, we discussed **eBURST**, originally developed to cluster conventional 7-gene MLST, and **GrapeTree**, which was recently developed to analyze genome-scale datasets.

Let's cluster the Hamming distance matrix by running the code chunk below:

```{r order distance matrix, results = 'hide'}
#  compute hierarchical clustering with hclust function and complete linkage method

hc <- dist_mat%>%
        as.dist() %>%
         hclust(method = "complete")

# reorder distance matrix according to the hc order 

dist_mat <- dist_mat[hc$order, hc$order]

# write reordered  distance matrix to files 
write.table(dist_mat, here("output","clusters","dist_mat_ordered_cgmlst.tsv"),
             quote = F, row.names = F, sep = "\t")
```

### Cluster extraction at multiple distance thresholds

Identifying clusters of genomes sharing highly similar cgMLST profiles through the application of distance thresholds is a common practice in genomic surveillance and epidemiological investigations. These genomic clusters can become "analytical units" that can be tracked across space and time:

- The detection of a novel genomic cluster comprising isolates from multiple human clinical cases can signal the emergence of an outbreak, thus requiring a public health response in order to contain further cases.  
- An examination of the evolving genomic cluster over time can provide important epidemiological insights on outbreak progression. 
- The co-clustering of outbreak isolates with isolates from food/environmental sources can assist epidemiologists investigating an outbreak by linking the outbreak isolates to isolates from possible sources/reservoirs of the pathogen.

Identifying cluster membership for every isolate in the dataset at multiple distance thresholds gives us the analytical flexibility to define suitable thresholds for analyzing the pathogen in question. From a practical perspective, a threshold that is too fine-grained will yield a large proportion of the dataset in singleton clusters, making it difficult to link outbreak isolates to one another and to potential outbreak sources. Conversely, using a threshold that is not fine-grained enough will fail to fully exploit the discriminatory power of genomic data, grouping outbreak and non-outbreak isolates indiscriminately.


> Adjusting similarity thresholds for cluster membership can be used to tweak the granularity of clusters: higher distance threshold produce larger clusters whereas lower distance thresholds will produce smaller clusters. A threshold of 0 will generate clusters with **identical** profiles.


In this section, we will harness the **awesome** power of the `cutree` R function to extract genomic clusters from the cgMLST dataset. This function allows us to generate cluster membership information at any given distance threshold, which can be used to generate summary tables that are foundational to computing genomic cluster statistics. The `cutree` function is infinitely flexible, allowing us to specify multiple distance cutoffs in parallel. In this lab, we will use this approach to compare how adjusting the threshold can be used to adjust the granularity of the resulting genomic clusters. We will then use cluster information to annotate a dendrogram. By analyzing cluster memberships and the associated metadata, we will look for possible outbreaks in the dataset. 

**For membership at all possible distance thresholds**, run the following code chunk:
```{r  clustter extraction at everything hold, results = 'hide'}

# Define genomic cluster membership at all possible distance thresholds

cgmlst_loci = (ncol(cgmlst_final)-1) ## maximum distance 
interval = 1  ##  edit interval of interest; currently set to 1 for all possible thresholds

thresholds <-  seq(0, cgmlst_loci,interval)


# extract cluster membership across multiple thresholds
cluster_membership <- map(thresholds, function(x) {
    hc %>% 
    cutree(h = x) %>% 
    as.factor()
})

# create name for each threshold
names(cluster_membership) <- paste0("Threshold_", thresholds)


# print clustering results table, no duplicated names are allowed
 (
clusters_all <- data.frame(cluster_membership ) %>%
    rownames_to_column("ID")
 )  

# reactable(clusters_all)

# write file of genomic cluster memberships at multiple thresholds
write.table(clusters_all, here("output","clusters","clusters_all.tsv"),
            quote = F, row.names = F, sep = "\t")

```

> **Questions:** How many distinct thresholds are theoretically possible for this dataset? How would you determine the maximum number of allele differences across all genomes in the dataset based on the table above? *hint: at some threshold, all genomes collapse to the same cluster...*

**For membership at select distance thresholds**, run the following code chunk:
```{r cluster extraction at user-defined distance thresholds,results = 'hide' }
# Define genomic cluster membership at user-defined distance thresholds

# Can either specify specific thresholds as a numeric vector i.e. c(0, 5, 10, 15) 
# If you're feeling lazy, you can also specify using c(seq(5, 100, 5)), which stands for "go from threshold 5 to 100 in
# increments of 5". You can also string multiple notations together within the same numerical vector.  

thresholds <-c(0, seq(5, 100, 5), seq(200, cgmlst_loci, 100))   # currently reads as "use threshold 0, 
                                                                # then from 5 to 100 in increments of 5
                                                                # then from 200 to maximum threshold 
                                                                # in increments of 100"

# extract cluster membership across multiple thresholds
 cluster_membership <- map(thresholds, function(x) {
     hc %>%
     cutree(h = x) %>%
     as.factor()
 })

# create name for each threshold
 names(cluster_membership) <- paste0("Threshold_", thresholds)

# print clustering results table, no duplicated names are allowed
 (
   user_defined_clusters <- data.frame(cluster_membership ) %>%
     rownames_to_column("ID")
   )

# write file
 write.table(user_defined_clusters, here("output","clusters","user_defined_clusters.tsv"),
             quote = F, row.names = F, sep = "\t")


```
> **Questions:** How many user-defined thresholds have we generated in the settings provided here? Which cluster does genome "ID9438" belong to at a threshold of 60 allele differences? How would you determine how many different clusters were generated at each particular threshold? 

### Genomic cluster summary tables

In this section, we will use the helper function `count_variables_by_cluster` to generate summary tables that calculate counts for variables of interest across all of the genomic clusters in the dataset defined at a particular threshold. These variables are based on categories and subcategories contained in the metadata table. For example, if one of the categories in the metadata table is "Source", the function will give us a breakdown of the source counts for each genomic cluster in the dataset (e.g. human, cattle, chicken, etc) . These cluster summaries can provide valuable insights on cluster composition, including regional, temporal, or source biases. Although such tables are not flashy, they are **very** useful for generating counts and statistics across **all** genomic clusters. 

Run the code chunk below:
```{r intercluster sumary table, message = FALSE}
# assign clusters_all to clusters for visualization  
clusters <- clusters_all 
summary_table <- count_variables_by_cluster(
# dist threshold used for cluster definition, can be adjusted; currently set to 50.
# Note: the specificed threshold must be one of the user-defined thresholds in previous section
    distance_threshold = 50, 
    vars = c("Source") # metadata variables to be used in cluster breakdown; currently using Source. 
                       # Can include more than one variable
    
 ) 

reactable(summary_table)  # to see complete table, click on the summary_table object in the Global Environment panel in the                           # top right hand corner -->
```
> **Questions:** How many human isolates are contained in cluster 22 at a threshold of 50 allele differences? Based on the characteristics of the cluster, what is the likely source of infection? What about cluster 24?  


## Day 2: Visualizations to facilitate analysis 

### Genomic cluster stacked histogram

Another useful tool in terms of exploring genomic cluster trends is to display cluster breakdown data such as we previously displayed in the summary tables described above in the form of a stacked histogram. The purpose of the function `cluster_summary` is to compare metadata variable distributions across all genomic clusters defined at a given distance threshold by generating one stacked histogram per metadata category. The resulting stacked histograms can be used to quickly scan through and examine all clusters for categorical variables to identify clusters with biased composition.

> Metadata variables can be used to probe for genomic clusters with specific biases (i.e. source, regional, temporal, etc). For example, you may identify a genomic cluster in which 60% of isolates a from human clinical isolates, indicating a lineage that poses a significant human health risk.

Run the following code chunk:

```{r intercluster analysis}
# Generate cluster summaries for stacked histograms
# NOTE: there needs to be a comma at the end of each line of code!
cluster_summary(
  distance_threshold = 50, # the distance threshold used for cluster definition; currently set to 50.
  clade_name = NULL, # which clade to include?
  vars = colnames(meta)[-1], # use metadata variables only
  panel.ncol = 2, # number of columns to arrange the panels into
  rm.low.freq.clust = T, # Filter to remove low frequency (N < 4) clusters
  interactive = T # True/False on whether to generate interactive plots. Currently set to T so that tooltips are enabled
)

```
> The stacked histogram above is interactive! Hover-over for a tooltip with additional cluster information. Also, remember that the plot can be popped out onto a separate window. **Questions:** Can you identify a T50 cluster larger than 10 genomes that is restricted to a single province? How about a cluster found across multiple decades? One with pronounced seasonal bias? Tell us *everything* you know about cluster 33?    


### Distance matrix visulization via ordered heatmap

A very useful visualization when dealing with distance matrices involves performing clustering, arranging the entries of the matrix based on the clustering order, and displaying the similarity as a heatmap. This produces a heatmap with a distinct 45 degree axis in which clusters of profiles with significant similarity representing possible clades/lineages can be plainly seen as "pockets of heat". In this section of the lab, we will visualize the distance matrix using the `ComplexHeatmap` package and we will be comparing these clades to available serotype information on the isolates by overlaying serotype information on the heatmap, which will allow us to examine whether the organism's serotype is concordant with putative lineages defined by cgMLST similarity as displayed on the clustered heatmap.

> In an era prior to various forms of molecular analysis, serotype was used as a proxy for genetic similarity of microbial isolates. For organisms like *Salmonella*, serotype determination is still a widely employed rapid screen. 

Let's run the code chunk below:

```{r distance matrix viz}
# create column annotations for heatmap
# to display clade information
set.seed(123)

heatmap_annot <-  metadata$Serotype
names(heatmap_annot) <-metadata$ID

heatmap_annot <- heatmap_annot[order(factor(names(heatmap_annot),
                                            levels = rownames(dist_mat)))]

# create heatmap
dist_mat %>% 
  Heatmap(
    name = "cgMLST\nDistance",
    show_row_names = F, # do not display row labels
    show_column_names = F, # do not display column labels
    # use custom color gradient
    col = colorRamp2(
      c(min(dist_mat), mean(dist_mat), max(dist_mat)),
      c("#f76c6a", "#eebd32", "#7ece97")
    ),
    
    # add column annotation to show serotype info overlaid on the clustered heatmap
    top_annotation = HeatmapAnnotation(
      Serotype= heatmap_annot,
      col = list(
      Serotype = structure(brewer.pal(length(unique(heatmap_annot)), "Set3"),
                                             names = unique(heatmap_annot))
      )
    )
  )
```

> **Questions:** Although many traits are essentially restricted to a single monophyletic genomic lineage, it is also possible that some traits are observed across multiple lineages and may therefore appear to be polyphyletic. Is there a serotype that looks like the latter? What is your interpretation of the last major "pocket" of heat at the bottom right of the heatmap? *bonus: although higher heat is seen along the 45 degree axis, there is some "residual" heat off-axis. What does it mean?*

## Annotated Dendrograms and cluster evaluation

Here you will convert hierarchical clustering result (hc) into a dendrogram using the `as.phylo()` function from the ape package. To visualize the resulting dendrogram, we will use the R package `ggtree`, which offers an extensive suite of functions to manipulate, visualize, and annotate tree-like data structures. In this section, you will be introduced to some of the different visual capabilities of `ggtree` and we will progressively update the same tree with several layers of visual annotations based on available metadata.

> Note that there is a massive amount of information in the interwebs dedicated to `ggtree` and all of its capabilities for advanced visualizations. Here we will barely scratch the surface.

### Circular vs. Rectangular dendrograms for simple tree visualization

Radial vs. Rectangular dendrograms are different ways of visualizing a tree. Radial trees are capable of displaying a lot of simple data in a smaller footprint. In contrast, rectangular trees can display more complex data in a visualization that is easy on the eyes. Rectangular trees rendered as pdf format allow you to really zoom into sub-branches of the tree in greater detail when viewed in a pdf reader or in a browser window. This is essential when you're dealing with larger datasets comprising hundreds of isolates such as the one we are dealing with here.

Run the following code chunks to:

1. Plot a circular tree of the entire dataset with the tree tips colored by serotype information. *You can assign a different metadata field to the `color_var` variable to update the mapping of the color aesthetics in the tree. For example setting `color_var = "Province"` will color the tree tips by the province of origin*.
2. Plot the same tree as a rectangular tree.

```{r clade tree, results = 'hide'}
# convert hierarchical clustering to a dendrogram 
set.seed(123)
cg_tree <- as.phylo(hc)

# also, write out the dendrogram to a Newick tree file, can be imported into ITOL or other tree visualization software for manual annotation
write.tree(cg_tree, file= here("output","trees","tree_complete_linkage.newick"))

# visualization with a color variable using R ggtree 
color_var <- "Serotype" # editable variable, currently set to "Serotype".

## filter out unknown serotypes to define the number of colors needed for remaining serotypes 
n_colors <- length(unique(pull(metadata, !!sym(color_var))))

## create circular dendrogram with variable-colored tippoints
cg_tree_cir <- cg_tree %>% 
  ggtree(layout='circular', # set tree shape 
         size = 1 # branch width
  )%<+% metadata +
  geom_tippoint(aes(color = !!sym(color_var)),
                size = 2,na.rm=TRUE) +
  guides(color = guide_legend(override.aes = list(size = 3) ) ) +
  scale_color_manual(values = distinctColorPalette(n_colors),na.value = "grey") #

cg_tree_cir


# Create rectangular tree with serotype tip points and text tip labels

# create tip labels 
metadata <- metadata %>%
            mutate(tip_lab = paste0(Province,"/ ",Date,"/ ",Source))

## plot    
set.seed(123)
  cg_tree %>% 
  ggtree(layout= "rectangular", # tree shape 
         size = 1 # branch width
  )%<+% metadata +
  geom_tippoint(aes(color = !!sym(color_var)),
                size = 2,na.rm=TRUE) +
  geom_tiplab(aes(label = tip_lab),  
              offset = 5,
              align = TRUE,
              linetype = NULL,
              size = 1) +theme_tree2()+
  geom_treescale(y = 370, x = 0.2) +
  guides(color = guide_legend(override.aes = list(size = 3) ) ) +
  scale_color_manual(values = distinctColorPalette(n_colors))
  
 # We save to pdf format
 ggsave(here("output","trees","clade_subtree_rec.pdf"), height = 45, width = 40)                 
```
> **Questions:** Between serotypes G and H, which one appears to be more heterogeneous based on cgMLST data? How would you improve the colour palette used to display serotype -- no, seriously?  


### Superimposing genomic cluster information onto dendrograms 

Let's now superimpose the genomic cluster information on the previous dendrograms (Radial & Rectangular) to examine whether the above code chunk for extracting cluster memberships at various thresholds has generated sensible cluster assignments. Run the code chunk below to insert text labels that span across tree tips assigned to the same clusters at [a specified threshold]{.underline}.

> You can edit the `target_threshold` variable to examine how cluster membership changes in response to clustering distance cutoffs.

Run the code chunk below for the radial tree:

```{r cg tree cluster viz}
# Radial tree visualization

# assign clusters_all to clusters for visualization  
clusters <- clusters_all 

target_threshold <- 50 # Editable variable,  currently set to a threshold of 50.

metadata<- metadata%>%
             select(-tip_lab)

# variable to subset clusters
target_variable <- paste0("Threshold_", target_threshold)

# create cluster group list object
cluster_grp <- clusters %>% 
  select(ID, target_variable) %>%
  group_by(!!sym(target_variable)) %>% 
  {setNames(group_split(.), group_keys(.)[[1]])} %>% 
  map(~pull(., ID))
# sequester singleton clusters
cluster_grp <- cluster_grp[which(map_dbl(cluster_grp, ~length(.)) > 10)]

# create clade group list object
meta2 <- metadata%>%
         filter(Serotype != "unknown")
Clade_grp <- meta2 %>% 
  select(ID, Serotype) %>% 
  split(f = as.factor(.$Serotype)) %>% 
  map(~pull(., ID))

# add cluster memberships and clade information to tree object
cg_tree <- groupOTU(cg_tree, cluster_grp, 'Clusters')
cg_tree <- groupOTU(cg_tree, Clade_grp, 'Serotype')

# plot core genome tree where colored blocks = clusters and text annotations = clades
cg_tree %>% 
  ggtree(layout='circular', # Editable tree shape, currently set to circular?
         size = 1 # branch width
  ) +
 
  # add colored blocks to display clades
  geom_hilight(
    mapping = aes(
      node = node,
      fill = Serotype,
      subset = node %in% map_dbl(
        Clade_grp,
        ~getMRCA(cg_tree, .)
        )
      )
    ) +
  #add text annotations to display clusters
  geom_cladelab(
    mapping = aes(
      node = node,
      label = Clusters,
      subset = node %in% map_dbl(
        cluster_grp,
        ~ getMRCA(cg_tree, .)
      )
    ),
    horizontal=T,
    angle = 'auto',
    barsize = 0.75,
    offset = 50,
    offset.text = 50,
    align = T
  ) +
  # legend parameters
  guides(fill = guide_legend(
    nrow = 11,
    override.aes = list(alpha = 0.8)
    )
  ) +
  labs(fill = "Serotype") +
  scale_fill_brewer(palette = "Paired")
```

> **Questions:** The radial dendrogram above displays serotype and also T50 cluster information for clusters larger than 10. What can you infer about the overall cgMLST similarity of genomes corresponding to serotype F? *hint: they're not all in the same T50 cluster...*

Run the code chunk below for the rectangular tree:

```{r clade subtree, fig.height = 25, fig.show = 'hide', message = F}
# Rectangulat tree visualization 
# NOTE: there needs to be a comma at the end of each line!

 serovar_subtree(
  tree = cg_tree,
  serovar_name = NULL, # which clade cluster to visualize?
  distance_threshold = 50, # the dist threshold used for cluster definition?
  color_by = "Serotype", # which metadata variable to color tree tips by?
  color.tiplab = F, # whether to color tip labels
  tip.size = 4, # size of tree tip point
  label_vars = c("geo_loc", "Date", "Source"), # metadata vars only
  label.offset = 80, # distance between labels and tree tips
  label.size = 2, # tree tip label text size
  legend.x = 0.1, # legend position on x axis
  legend.y = 0.98, # legend position on y axis
  legend.size = 6, # legend text size
  legend.ncat.per.col = 8, # number of categories to show per column in legend
  hide.legend = F, # whether to hide colour legend
  plot.xlim = 2300, # plot area width
  annot.offset = 3, # distance between heatmap and tree tips
  annot.textsize = 5, # heatmap x axis text label size
  annot.barsize = 0.75, # annotation bar width
  show.title = T # whether to display distance threshold
)

# We export the tree to pdf format in the /output/trees folder (clade_subtree2.pdf; 
# check the folder navigation pane at the bottom right). 
# The file can be dropped into a web browser so you can zoom into individual genomic clusters.
ggsave(here("output","trees","clade_subtree2.pdf"), height = 45, width = 60,limitsize = FALSE)

```
> **Questions:** The tree above is rendered too small in R studio to be of any use except to ruin your eyes. Open the corresponding pdf file (/output/trees/clade_subtree2.pdf) on your web browser. How many T50 clusters are associated with serotype F? What can you tell us about T50 clusters 30 and 46?


### Displaying a specific cluster subtree
In order to examine the clustering patterns in the cgMLST dendrogram at greater resolutions, we will work with a number of R functions introduced below. These functions are used in conjunction to zoom in on specific sublineages so that we may further explore the strains within. The purpose of the function `cluster_subtree` is to visualize subtrees of specific clusters defined at a given distance threshold. The cluster is defined by its ID and the distance threshold used for genomic cluster assignment, which are defined by the variables `cluster_name` and `distance_threshold`, respectively. We recommend scanning the summary tables or stacked histograms used above to look for clusters that may merit some zooming into.

Run the following code chunk:
```{r cluster subtree, fig.height = 6, message = F}
# NOTE: there needs to be a comma at the end of each line!

Threshold <- paste0("Threshold_", c(0, 10, 20, 30, 40, 50)) # User-defined thresholds specified in the 
                                                            # distance vector. 
                                                            # Currently set to 0, 10, 20, 30 40, 50
Cluster_tree <- clusters %>% 
                select(ID,Threshold)  # This line selects the cluster+treshold combination 
                                      # for the subtree visualization
                                      

## plot tree
cluster_subtree(
  tree = cg_tree,
  clusters = Cluster_tree,
  distance_threshold = 50, # the dist threshold used for cluster definition, from the list in L767
  cluster_name = "24", # Cluster ID to visualize. 
  color_by = "Season", # Metadata variable to color tree tips by; currently set to Province
  color.tiplab = F, # whether to color tip labels
  tip.size = 3, # size of tree tip point
  legend.x = 0.1, # legend position on x axis
  legend.y = 0.85, # legend position on y axis
  legend.size = 5, # legend text size
  legend.ncat.per.col = 8, # number of categories to show per column in legend
  hide.legend = F, # whether to hide colour legend
  plot.xlim = 60, # plot area width
  label_vars = c("ID", "Province", "Date", "Source"), # User can add any metadata variable to display
  label.offset = 9.2, # distance between labels and tree tips
  label.size = 4, # tree tip label text size
  annot.offset = 0.1, # distance between heatmap and tree tips
  annot.width = 0.3, # heatmap width
  annot.textsize = 4, # heatmap x axis text label size
  annot.nthreshold = 6 # number of clustering thresholds to display

  # note: the visualization below has been tweaked for optimal viewing of 6 thresholds. Adjustment to the various 
  # parameters above may be necessary if adding or removing additional thresholds to improve legibility in the subtree
    
)
```

> **Questions:** What distance threshold is necessary to tease apart the fact that strain ID09120 *is not like the others*? Taking into account that we are labeling the leaves of the tree using information for "Season", what can you say about the set of isolates from ID04684 to ID05454 as we go from a threshold of 10 allele differences down to a thresdhold of 0?


### Ah, we see you're done...a little early...

Using the rectangular dendrogram with enhanced annotations provided, which was generated using [**iTOL**](https://itol.embl.de/#), find genomic clusters that fit the following criteria and consider possible scenarios for interpretation of genomic data and epidemiological metadata:

    a.  A genomic cluster that at T50 splits into multiple multi-strain subclusters when examined at T0
    
    b.  Find a polyphyletic serovar (again)

    c.  A genomic cluster comprising human clinical cases with similar geographical and temporal information

    d.  A genomic cluster in which the human clinical cases are dispersed in geography and/or time

    e.  A genomic cluster in which human clinical isolates cluster with non-human isolates from a common source type

    f.  A genomic cluster in which human clinical isolates cluster with non-human isolates from multiple source types.
    
    g.  What's the story on T20 cluster #102? 
    
    h.  **Bonus Question:** How would you define the "optimal" distance threshold for extracting and reporting genomic clusters? State your position...


> `ggtree` is certainly an excellent tool but there is definitely a bit of a learning curve, though there is also a lot of material online. For building trees with more complex annotations, a good option is **iTOL**, though it certainly has a learning curve of its own.


### Some final points to remember...
Note that it's important to remind ourselves that outbreaks lie along a spectrum in their genetic and epidemiological characteristics and this will be reflected in terms of how clustering and metadata annotations will show up on a dendrogram/subtree, or in the breakdown of metadata variables across genomic clusters. Some outbreaks are typified by highly genetically similar isolates from clinical cases that are highly restricted in time and space (e.g. the point-source outbreak where some people at the picnic ate the potato salad contaminated with a single strain of the pathogen). At the other end of the scale, some outbreaks comprise genetically heterogeneous pathogen isolates from clinical cases that are dispersed in time and/or space (e.g. people exposed through consumption of a nationally-distributed food product contaminated with several strains during a production run). Thus, identifying an outbreak from genomic surveillance data alone is not always possible. Although genomic data represents strong evidence in an outbreak investigation, there is no substitute for some good 'ol **shoe-leather epidemiology** to place everything in context.
